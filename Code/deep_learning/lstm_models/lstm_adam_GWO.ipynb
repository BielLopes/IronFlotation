{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mealpy.swarm_based import GWO\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>% Iron Feed</th>\n",
       "      <th>% Silica Feed</th>\n",
       "      <th>Starch Flow</th>\n",
       "      <th>Amina Flow</th>\n",
       "      <th>Ore Pulp Flow</th>\n",
       "      <th>Ore Pulp pH</th>\n",
       "      <th>Ore Pulp Density</th>\n",
       "      <th>Flotation Column 01 Air Flow</th>\n",
       "      <th>Flotation Column 02 Air Flow</th>\n",
       "      <th>...</th>\n",
       "      <th>Flotation Column 07 Air Flow</th>\n",
       "      <th>Flotation Column 01 Level</th>\n",
       "      <th>Flotation Column 02 Level</th>\n",
       "      <th>Flotation Column 03 Level</th>\n",
       "      <th>Flotation Column 04 Level</th>\n",
       "      <th>Flotation Column 05 Level</th>\n",
       "      <th>Flotation Column 06 Level</th>\n",
       "      <th>Flotation Column 07 Level</th>\n",
       "      <th>% Iron Concentrate</th>\n",
       "      <th>% Silica Concentrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-29 12:00:00</td>\n",
       "      <td>60.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1063.45</td>\n",
       "      <td>379.6</td>\n",
       "      <td>400.97</td>\n",
       "      <td>9.53</td>\n",
       "      <td>1.55</td>\n",
       "      <td>200.04</td>\n",
       "      <td>195.57</td>\n",
       "      <td>...</td>\n",
       "      <td>249.99</td>\n",
       "      <td>755.38</td>\n",
       "      <td>728.0</td>\n",
       "      <td>862.04</td>\n",
       "      <td>477.46</td>\n",
       "      <td>452.56</td>\n",
       "      <td>478.22</td>\n",
       "      <td>469.82</td>\n",
       "      <td>66.45</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-29 13:00:00</td>\n",
       "      <td>60.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>2032.86</td>\n",
       "      <td>322.95</td>\n",
       "      <td>400.47</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1.54</td>\n",
       "      <td>199.99</td>\n",
       "      <td>195.13</td>\n",
       "      <td>...</td>\n",
       "      <td>250.07</td>\n",
       "      <td>848.67</td>\n",
       "      <td>777.59</td>\n",
       "      <td>869.45</td>\n",
       "      <td>483.95</td>\n",
       "      <td>469.64</td>\n",
       "      <td>471.67</td>\n",
       "      <td>462.91</td>\n",
       "      <td>66.58</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-29 14:00:00</td>\n",
       "      <td>60.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1426.1</td>\n",
       "      <td>474.89</td>\n",
       "      <td>399.15</td>\n",
       "      <td>9.69</td>\n",
       "      <td>1.65</td>\n",
       "      <td>200.03</td>\n",
       "      <td>195.58</td>\n",
       "      <td>...</td>\n",
       "      <td>250.11</td>\n",
       "      <td>852.0</td>\n",
       "      <td>776.32</td>\n",
       "      <td>879.69</td>\n",
       "      <td>455.97</td>\n",
       "      <td>453.18</td>\n",
       "      <td>447.52</td>\n",
       "      <td>453.63</td>\n",
       "      <td>66.64</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-29 15:00:00</td>\n",
       "      <td>60.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>616.73</td>\n",
       "      <td>395.13</td>\n",
       "      <td>398.94</td>\n",
       "      <td>9.86</td>\n",
       "      <td>1.56</td>\n",
       "      <td>199.94</td>\n",
       "      <td>195.61</td>\n",
       "      <td>...</td>\n",
       "      <td>250.04</td>\n",
       "      <td>855.89</td>\n",
       "      <td>780.4</td>\n",
       "      <td>882.1</td>\n",
       "      <td>449.4</td>\n",
       "      <td>448.52</td>\n",
       "      <td>450.87</td>\n",
       "      <td>448.41</td>\n",
       "      <td>66.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-29 16:00:00</td>\n",
       "      <td>59.54</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1369.26</td>\n",
       "      <td>318.08</td>\n",
       "      <td>400.82</td>\n",
       "      <td>9.94</td>\n",
       "      <td>1.54</td>\n",
       "      <td>199.89</td>\n",
       "      <td>196.25</td>\n",
       "      <td>...</td>\n",
       "      <td>250.12</td>\n",
       "      <td>851.58</td>\n",
       "      <td>784.47</td>\n",
       "      <td>884.86</td>\n",
       "      <td>450.22</td>\n",
       "      <td>451.9</td>\n",
       "      <td>451.58</td>\n",
       "      <td>449.39</td>\n",
       "      <td>63.65</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Data % Iron Feed % Silica Feed Starch Flow Amina Flow  \\\n",
       "0 2017-03-29 12:00:00       60.18          9.35     1063.45      379.6   \n",
       "1 2017-03-29 13:00:00       60.18          9.35     2032.86     322.95   \n",
       "2 2017-03-29 14:00:00       60.18          9.35      1426.1     474.89   \n",
       "3 2017-03-29 15:00:00       60.18          9.35      616.73     395.13   \n",
       "4 2017-03-29 16:00:00       59.54          9.56     1369.26     318.08   \n",
       "\n",
       "  Ore Pulp Flow Ore Pulp pH Ore Pulp Density Flotation Column 01 Air Flow  \\\n",
       "0        400.97        9.53             1.55                       200.04   \n",
       "1        400.47        9.71             1.54                       199.99   \n",
       "2        399.15        9.69             1.65                       200.03   \n",
       "3        398.94        9.86             1.56                       199.94   \n",
       "4        400.82        9.94             1.54                       199.89   \n",
       "\n",
       "  Flotation Column 02 Air Flow  ... Flotation Column 07 Air Flow  \\\n",
       "0                       195.57  ...                       249.99   \n",
       "1                       195.13  ...                       250.07   \n",
       "2                       195.58  ...                       250.11   \n",
       "3                       195.61  ...                       250.04   \n",
       "4                       196.25  ...                       250.12   \n",
       "\n",
       "  Flotation Column 01 Level Flotation Column 02 Level  \\\n",
       "0                    755.38                     728.0   \n",
       "1                    848.67                    777.59   \n",
       "2                     852.0                    776.32   \n",
       "3                    855.89                     780.4   \n",
       "4                    851.58                    784.47   \n",
       "\n",
       "  Flotation Column 03 Level Flotation Column 04 Level  \\\n",
       "0                    862.04                    477.46   \n",
       "1                    869.45                    483.95   \n",
       "2                    879.69                    455.97   \n",
       "3                     882.1                     449.4   \n",
       "4                    884.86                    450.22   \n",
       "\n",
       "  Flotation Column 05 Level Flotation Column 06 Level  \\\n",
       "0                    452.56                    478.22   \n",
       "1                    469.64                    471.67   \n",
       "2                    453.18                    447.52   \n",
       "3                    448.52                    450.87   \n",
       "4                     451.9                    451.58   \n",
       "\n",
       "  Flotation Column 07 Level % Iron Concentrate % Silica Concentrate  \n",
       "0                    469.82              66.45                 1.37  \n",
       "1                    462.91              66.58                 1.43  \n",
       "2                    453.63              66.64                 1.33  \n",
       "3                    448.41               66.4                  1.3  \n",
       "4                    449.39              63.65                 5.48  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_unformatted = pd.read_csv(\"./CompiledMeanDataRounded.csv\", decimal=\",\", parse_dates=[\"Data\"], infer_datetime_format=True).drop_duplicates()\n",
    "data_set_unformatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3948, 24)\n"
     ]
    }
   ],
   "source": [
    "data_set_unformatted = data_set_unformatted.to_numpy()\n",
    "print(data_set_unformatted.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3948, 22)\n"
     ]
    }
   ],
   "source": [
    "data_set_unformatted = data_set_unformatted[:,1:-1]\n",
    "print(data_set_unformatted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_unformatted = np.array(data_set_unformatted, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.empty(data_set_unformatted.shape)\n",
    "for i in range(data_set_unformatted.shape[1]):\n",
    "    tag_max = np.max(data_set_unformatted[:, i])\n",
    "    tag_min = np.min(data_set_unformatted[:, i])\n",
    "    scope = tag_max - tag_min\n",
    "    \n",
    "    for j in range(data_set_unformatted.shape[0]):\n",
    "        data_set[j, i] = (data_set_unformatted[j, i] - tag_min)/scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão do dados em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 2769\n",
      "Test Samples: 1173\n"
     ]
    }
   ],
   "source": [
    "training_data = data_set[:2775,:]\n",
    "test_data = data_set[2769:,:]\n",
    "\n",
    "print(f\"Training Samples: {training_data.shape[0] - 6}\")\n",
    "print(f\"Test Samples: {test_data.shape[0] - 6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "FEATURES_INPUT = data_set.shape[1] * 6\n",
    "print(FEATURES_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2769, 132)\n",
      "(2769, 1)\n"
     ]
    }
   ],
   "source": [
    "training_input = np.empty((training_data.shape[0] - 6, FEATURES_INPUT), dtype=np.float32)\n",
    "training_label = np.empty((training_data.shape[0] - 6, 1), dtype=np.float32)\n",
    "\n",
    "for i in range(6, training_data.shape[0]):\n",
    "    training_input[i - 6,:] = training_data[i:i-6:-1,:].reshape(FEATURES_INPUT)\n",
    "    training_label[i - 6] = training_data[i, 21]\n",
    "\n",
    "print(training_input.shape)\n",
    "print(training_label.shape)\n",
    "\n",
    "training_input = torch.from_numpy(training_input)\n",
    "training_label = torch.from_numpy(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([132, 1173])\n",
      "torch.Size([1, 1173])\n"
     ]
    }
   ],
   "source": [
    "test_input = np.empty((test_data.shape[0] - 6, FEATURES_INPUT), dtype=np.float32)\n",
    "test_label = np.empty((test_data.shape[0] - 6, 1), dtype=np.float32)\n",
    "\n",
    "for i in range(6, test_data.shape[0]):\n",
    "    test_input[i - 6,:] = test_data[i:i-6:-1,:].reshape(FEATURES_INPUT)\n",
    "    test_label[i - 6]   = test_data[i, 21]\n",
    "\n",
    "test_input = torch.from_numpy(test_input)\n",
    "test_label = torch.from_numpy(test_label)\n",
    "\n",
    "test_input = torch.transpose(test_input, 0, 1)\n",
    "test_label = torch.transpose(test_label, 0, 1)\n",
    "\n",
    "print(test_input.size())\n",
    "print(test_label.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, hidden_layers, n_hidden, input_size):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.input_size = input_size\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.lstm_input = nn.LSTMCell(self.input_size, self.n_hidden )\n",
    "        self.lstm_list = nn.ModuleList()\n",
    "        for i in range(self.hidden_layers): self.lstm_list.append(nn.LSTMCell(self.n_hidden , self.n_hidden )) \n",
    "        self.linear = nn.Linear(self.n_hidden , 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = []\n",
    "        n_samples = 1\n",
    "\n",
    "        h_t = torch.zeros(n_samples, self.n_hidden , dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.n_hidden , dtype=torch.float32)\n",
    "        h_t_list = [torch.zeros(n_samples, self.n_hidden , dtype=torch.float32) for i in range(self.hidden_layers)]\n",
    "        c_t_list = [torch.zeros(n_samples, self.n_hidden , dtype=torch.float32) for i in range(self.hidden_layers)]\n",
    "\n",
    "        for input_t in input.split(1, dim=1):\n",
    "            input_t = torch.transpose(input_t, 0, 1)\n",
    "            h_t, c_t = self.lstm_input(input_t, (h_t, c_t))\n",
    "\n",
    "            for layer in range(self.hidden_layers):\n",
    "                h_in = None\n",
    "                if layer == 0:\n",
    "                    h_in = h_t\n",
    "                else:\n",
    "                    h_in = h_t_list[layer-1]\n",
    "\n",
    "                h_t_list[layer], c_t_list[layer] = self.lstm_list[layer](h_in, (h_t_list[layer], c_t_list[layer]))\n",
    "            \n",
    "            h_t_out = h_t_list[-1]\n",
    "            output = self.linear(h_t_out)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria e executa Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execution(hidden_layers, hidden_size, learning_rate):\n",
    "    \n",
    "    HIDDEN_SIZE = hidden_size\n",
    "    model = LSTMPredictor(hidden_layers, HIDDEN_SIZE, FEATURES_INPUT)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train(line_tensor, category_tensor):\n",
    "        line_tensor = torch.transpose(line_tensor, 0, 1)\n",
    "        category_tensor = torch.transpose(category_tensor, 0, 1)\n",
    "\n",
    "        out = model(line_tensor)\n",
    "        loss = criterion(out, category_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    batch_size = 32\n",
    "\n",
    "    def random_sample():\n",
    "        start = np.random.randint(training_input.shape[0] - batch_size)\n",
    "        return training_input[start:start+batch_size,:], training_label[start:start+batch_size,:]\n",
    "\n",
    "    n_epochs = 0\n",
    "    max_epochs = 50\n",
    "    n_batches = 42\n",
    "    desirable_loss = 0.003\n",
    "\n",
    "    new_loss = 1\n",
    "\n",
    "    all_losses = []\n",
    "\n",
    "    for i in range(max_epochs):\n",
    "        n_epochs += 1\n",
    "        \n",
    "        for k in range(n_batches):\n",
    "            input_batch, category_batch = random_sample()\n",
    "\n",
    "            train(input_batch, category_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(test_input)\n",
    "            loss = criterion(out, test_label)\n",
    "            new_loss = loss.item()\n",
    "\n",
    "            # print(f\"epoch {i+1}: {new_loss}\")\n",
    "            all_losses.append(new_loss)\n",
    "\n",
    "            if new_loss < desirable_loss:\n",
    "                break\n",
    "\n",
    "    print(\"#####################################################################################\")\n",
    "    print(f\"Hidden Layers: {hidden_layers} | Hidden Size: {hidden_size} | Learning Rate: {learning_rate:.5} | N_epochs: {n_epochs}\")\n",
    "    print(\"#####################################################################################\")\n",
    "\n",
    "    return n_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função a ser otimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(solution):\n",
    "    n_epochs = model_execution(int(solution[0]), int(solution[1]), solution[2]) # hidden_layers, hidden_size, learning_rate\n",
    "    return n_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema e restrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {\n",
    "    \"fit_func\": fitness_function,\n",
    "    \"lb\": [1, 10, 0.0001],\n",
    "    \"ub\": [6, 61, 0.01],\n",
    "    \"minmax\": \"min\",\n",
    "    \"log_to\": None,\n",
    "    \"save_population\": False,\n",
    "}\n",
    "\n",
    "max_evaluations = {\n",
    "   \"mode\": \"FE\",\n",
    "   \"quantity\": 800\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar Otimização de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GWO.OriginalGWO(epoch=100, pop_size=12, pr=0.03)\n",
    "best_position, best_fitness = model.solve(problem, termination=max_evaluations)\n",
    "print(f\"Best solution: {best_position}, Best fitness: {best_fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
